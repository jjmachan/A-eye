{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets\n",
    "\n",
    "This contains the definitions for all the datasets used for the experiments.\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import json\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "\n",
    "annotations = namedtuple('Annotations',['image_id','sentences'])\n",
    "\n",
    "class Flickr8k(Dataset):\n",
    "    \"\"\" for flickr 8k dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, img_dir, ann_file, split='train', transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (str): The root dir that points to the Flickr images.\n",
    "            ann_file (str): The file that contains the annotations for the images.\n",
    "            split ['train', 'val', 'test']: This decides which partition to load.\n",
    "            transform: Transforms for image.\n",
    "            target_transforms: transforms for sentences.\n",
    "        \"\"\"\n",
    "        self.img_dir = Path(img_dir)\n",
    "        assert split in ['train', 'test', 'val']\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.annotations = list()\n",
    "        \n",
    "        # indices when spliting the json file\n",
    "        if self.split == 'train':\n",
    "            m, n = 0, 6000\n",
    "        elif self.split == 'val':\n",
    "            m, n = 6000, 7000\n",
    "        elif self.split == 'test':\n",
    "            m, n = 7000, 8000\n",
    "            \n",
    "        with open(ann_file, 'r') as ann_file:\n",
    "            ann_json = json.load(ann_file)\n",
    "            for image in ann_json['images'][m : n]:\n",
    "                image_id = image['filename']\n",
    "                sentences_list = list()\n",
    "                for sentence in image['sentences']:\n",
    "                    sentences_list.append(sentence['tokens'])\n",
    "                self.annotations.append(annotations(image_id, sentences_list))\n",
    "                \n",
    "                assert image['split'] == self.split\n",
    "                \n",
    "            print('loading %s complete'%(self.split))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.annotations[index].image_id\n",
    "        \n",
    "        img = Image.open(self.img_dir/img_id).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        # Captions\n",
    "        target = self.annotations[index].sentences\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        \n",
    "        return img_id, img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr8k_dir = '/home/jithin/datasets/imageCaptioning/flicker8k/Flicker8k_Dataset'\n",
    "captions_file = '/home/jithin/datasets/imageCaptioning/captions/dataset_flickr8k.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading val complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Flickr8k(flickr8k_dir, captions_file, split='val')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=500x333 at 0x7F84BC346BE0>,\n",
       " [['the',\n",
       "   'boy',\n",
       "   'laying',\n",
       "   'face',\n",
       "   'down',\n",
       "   'on',\n",
       "   'a',\n",
       "   'skateboard',\n",
       "   'is',\n",
       "   'being',\n",
       "   'pushed',\n",
       "   'along',\n",
       "   'the',\n",
       "   'ground',\n",
       "   'by',\n",
       "   'another',\n",
       "   'boy'],\n",
       "  ['two', 'girls', 'play', 'on', 'a', 'skateboard', 'in', 'a', 'courtyard'],\n",
       "  ['two', 'people', 'play', 'on', 'a', 'long', 'skateboard'],\n",
       "  ['two',\n",
       "   'small',\n",
       "   'children',\n",
       "   'in',\n",
       "   'red',\n",
       "   'shirts',\n",
       "   'playing',\n",
       "   'on',\n",
       "   'a',\n",
       "   'skateboard'],\n",
       "  ['two',\n",
       "   'young',\n",
       "   'children',\n",
       "   'on',\n",
       "   'a',\n",
       "   'skateboard',\n",
       "   'going',\n",
       "   'across',\n",
       "   'a',\n",
       "   'sidewalk']])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
